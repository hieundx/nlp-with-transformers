{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['books', 'electronics', 'grocery', 'movies', 'restaurants', 'tripadvisor']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "# suppress warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "domains = get_dataset_config_names('subjqa')\n",
    "domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "subjqa  = load_dataset('subjqa', name='electronics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['Bass is weak as expected', 'Bass is weak as expected, even with EQ adjusted up'], 'answer_start': [1302, 1302], 'answer_subj_level': [1, 1], 'ans_subj_score': [0.5083333253860474, 0.5083333253860474], 'is_ans_subjective': [True, True]}\n"
     ]
    }
   ],
   "source": [
    "sample = subjqa['train'][1]\n",
    "print(sample['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions in train: 1295\n",
      "Number of questions in test: 358\n",
      "Number of questions in validation: 255\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs = {\n",
    "    split: dset.to_pandas() for split, dset in subjqa.flatten().items()\n",
    "}\n",
    "\n",
    "for split, df in dfs.items():\n",
    "    print(f\"Number of questions in {split}: {df['id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>answers.text</th>\n",
       "      <th>answers.answer_start</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>B005DKZTMG</td>\n",
       "      <td>Does the keyboard lightweight?</td>\n",
       "      <td>[this keyboard is compact]</td>\n",
       "      <td>[215]</td>\n",
       "      <td>I really like this keyboard.  I give it 4 star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>B00AAIPT76</td>\n",
       "      <td>How is the battery?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>I bought this after the first spare gopro batt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title                        question                answers.text  \\\n",
       "791   B005DKZTMG  Does the keyboard lightweight?  [this keyboard is compact]   \n",
       "1159  B00AAIPT76             How is the battery?                          []   \n",
       "\n",
       "     answers.answer_start                                            context  \n",
       "791                 [215]  I really like this keyboard.  I give it 4 star...  \n",
       "1159                   []  I bought this after the first spare gopro batt...  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_cols = ['title', 'question', 'answers.text', 'answers.answer_start', 'context']\n",
    "sample_df = dfs['train'][qa_cols].sample(2, random_state=7)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this keyboard is compact'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyboard_qa = sample_df.iloc[0]\n",
    "start_index = keyboard_qa['answers.answer_start'][0] # arr of len 1\n",
    "end_index = start_index + len(keyboard_qa['answers.text'][0]) # arr of len 1\n",
    "keyboard_qa['context'][start_index: end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_ckpt = 'deepset/minilm-uncased-squad2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2129,  2172,  2189,  2064,  2023,  2907,  1029,   102,  2019,\n",
       "         23378,  2003,  2055,  1015, 16914,  1013,  3371,  1010,  2061,  2055,\n",
       "         25961,  2847,  5834,  2006,  5371,  2946,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How much music can this hold?\"\n",
    "context = \"\"\"An MP3 is about 1 MB/minute, so about 6000 hours depending on \\\n",
    "file size.\"\"\"\n",
    "\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] how much music can this hold? [SEP] an mp3 is about 1 mb / minute, so about 6000 hours depending on file size. [SEP]'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/minilm-uncased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-0.9862, -4.7750, -5.4025, -5.2378, -5.2863, -5.5117, -4.9819, -6.1880,\n",
      "         -0.9862,  0.2596, -0.2144, -1.7136,  3.7806,  4.8561, -1.0546, -3.9097,\n",
      "         -1.7374, -4.5944, -1.4278,  3.9949,  5.0391, -0.2018, -3.0193, -4.8549,\n",
      "         -2.3107, -3.5110, -3.5713, -0.9862]]), end_logits=tensor([[-0.9623, -5.4733, -5.0326, -5.1639, -5.4278, -5.5151, -5.1749, -4.6233,\n",
      "         -0.9623, -3.7855, -0.8715, -3.7745, -3.0161, -1.1780,  0.1758, -2.7365,\n",
      "          4.8934,  0.3046, -3.1761, -3.2762,  0.8937,  5.6606, -0.3623, -4.9554,\n",
      "         -3.2531, -0.0914,  1.6211, -0.9623]]), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_ckpt)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ID shape:  torch.Size([1, 28])\n",
      "Start logits shape:  torch.Size([1, 28])\n",
      "End logits shape:  torch.Size([1, 28])\n"
     ]
    }
   ],
   "source": [
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "\n",
    "print('Input ID shape: ', inputs.input_ids.shape)\n",
    "print('Start logits shape: ', start_logits.shape)\n",
    "print('End logits shape: ', end_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: How much music can this hold?\n",
      "A: 6000 hours\n"
     ]
    }
   ],
   "source": [
    "start_idx = torch.argmax(start_logits)\n",
    "end_idx = torch.argmax(end_logits) + 1\n",
    "answer_span = inputs.input_ids[0, start_idx:end_idx]\n",
    "\n",
    "run_result = tokenizer.decode(answer_span)\n",
    "print('Q:', question)\n",
    "print('A:', run_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.26516246795654297,\n",
       "  'start': 38,\n",
       "  'end': 48,\n",
       "  'answer': '6000 hours'},\n",
       " {'score': 0.22082945704460144,\n",
       "  'start': 16,\n",
       "  'end': 48,\n",
       "  'answer': '1 MB/minute, so about 6000 hours'},\n",
       " {'score': 0.10253474116325378,\n",
       "  'start': 16,\n",
       "  'end': 27,\n",
       "  'answer': '1 MB/minute'}]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline('question-answering', model=model, tokenizer=tokenizer)\n",
    "pipe(question=question, context=context, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.6698799729347229, 'start': 16, 'end': 20, 'answer': '1 MB'},\n",
       " {'score': 0.113197460770607, 'start': 18, 'end': 20, 'answer': 'MB'},\n",
       " {'score': 0.10320844501256943,\n",
       "  'start': 16,\n",
       "  'end': 27,\n",
       "  'answer': '1 MB/minute'}]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(question='how much can an MP3 hold in 1 minute?', context=context, top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with long context by using sliding window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "example = dfs['train'].iloc[0][['question', 'context']]\n",
    "tokenized_example = tokenizer(\n",
    "    example['question'], \n",
    "    example['context'],\n",
    "    \n",
    "    # sliding window paramters\n",
    "    return_overflowing_tokens=True,\n",
    "    max_length=100,\n",
    "    stride=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_example['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 0:\n",
      "[CLS] how is the bass? [SEP] i have had koss headphones in the past, pro 4aa and qz - 99. the koss portapro is portable and has great bass response. the work great with my android phone and can be \" rolled up \" to be carried in my motorcycle jacket or computer bag without getting crunched. they are very light and do not feel heavy or bear down on your ears even after listening to music with them on all day. the sound is [SEP]\n",
      "100 tokens\n",
      "\n",
      "Window 1:\n",
      "[CLS] how is the bass? [SEP] and do not feel heavy or bear down on your ears even after listening to music with them on all day. the sound is night and day better than any ear - bud could be and are almost as good as the pro 4aa. they are \" open air \" headphones so you cannot match the bass to the sealed types, but it comes close. for $ 32, you cannot go wrong. [SEP]\n",
      "88 tokens\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, window in enumerate(tokenized_example['input_ids']):\n",
    "    print(f\"Window {idx}:\")\n",
    "    print(tokenizer.decode(window))\n",
    "    print(len(window), 'tokens')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Haystack to build QA pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack_integrations.document_stores.elasticsearch import ElasticsearchDocumentStore\n",
    "from haystack import Document\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(\n",
    "    hosts = \"http://localhost:9200\",\n",
    ")\n",
    "\n",
    "document_store.count_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split, df in dfs.items():\n",
    "    docs = [\n",
    "        {\n",
    "            'content': row['context'],\n",
    "            'meta': {\n",
    "                'item_id': row['title'],\n",
    "                'question_id': row['id'],\n",
    "                'split': split\n",
    "            }\n",
    "        }\n",
    "        for _, row in df.drop_duplicates(subset='context').iterrows()\n",
    "    ]\n",
    "    # document_store.write_documents([\n",
    "    #     Document(**doc)\n",
    "    #     for doc in docs\n",
    "    # ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store.count_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack_integrations.components.retrievers.elasticsearch import ElasticsearchBM25Retriever\n",
    "es_retriever = ElasticsearchBM25Retriever(\n",
    "    document_store=document_store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id = \"B0074BW614\"\n",
    "query = question\n",
    "filters = {\n",
    "    'operator': 'AND',\n",
    "    'conditions': [\n",
    "        {\n",
    "            'field': 'meta.item_id',\n",
    "            'value': item_id,\n",
    "            'operator': '=='\n",
    "        },\n",
    "        {\n",
    "            'field': 'meta.split',\n",
    "            'value': 'train',\n",
    "            'operator': '==',\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "retrieved_docs = es_retriever.run(\n",
    "    query=query,\n",
    "    top_k=3,\n",
    "    filters=filters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B0074BW614 train\n",
      "B0074BW614 train\n",
      "B0074BW614 train\n"
     ]
    }
   ],
   "source": [
    "for doc in retrieved_docs['documents']:\n",
    "    print(doc.meta['item_id'], doc.meta['split'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.readers import ExtractiveReader\n",
    "\n",
    "model_ckpt = 'deepset/minilm-uncased-squad2'\n",
    "max_seq_length, doc_stride = 384, 128\n",
    "reader = ExtractiveReader(\n",
    "    model=model_ckpt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/minilm-uncased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "reader.warm_up()\n",
    "run_result = reader.run(\n",
    "    query=question,\n",
    "    documents=retrieved_docs['documents'],\n",
    "    top_k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much music can this hold?\n",
      "no music\n",
      "all my music from iTunes\n",
      "Cloud Player\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(question)\n",
    "\n",
    "for ans in run_result['answers']:\n",
    "    print(ans.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reader': {'answers': [ExtractedAnswer(query='How much music can this hold?', score=0.6685347557067871, data='stream if a phone call comes in at the same time', document=Document(id=b6d3a0fbe7c2fd4a0e236444d07e3113ebe0d8685607e96ad69f5c14771b6c11, content: 'I never imagined I would spend $200 on a tiny wireless speaker system but the rave review by David P...', meta: {'item_id': 'B004E10KFG', 'question_id': '1b1d92228cac6fef9eee45496f6f101f', 'split': 'train'}, score: 11.0743265), context=None, document_offset=ExtractedAnswer.Span(start=1258, end=1306), context_offset=None, meta={}),\n",
       "   ExtractedAnswer(query='How much music can this hold?', score=0.6322438716888428, data='12oz', document=Document(id=b6d3a0fbe7c2fd4a0e236444d07e3113ebe0d8685607e96ad69f5c14771b6c11, content: 'I never imagined I would spend $200 on a tiny wireless speaker system but the rave review by David P...', meta: {'item_id': 'B004E10KFG', 'question_id': '1b1d92228cac6fef9eee45496f6f101f', 'split': 'train'}, score: 11.0743265), context=None, document_offset=ExtractedAnswer.Span(start=1375, end=1379), context_offset=None, meta={}),\n",
       "   ExtractedAnswer(query='How much music can this hold?', score=0.12189837491098388, data=None, document=None, context=None, document_offset=None, context_offset=None, meta={})]}}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "\n",
    "pipe = Pipeline()\n",
    "pipe.add_component(instance=es_retriever, name='retriever')\n",
    "pipe.add_component(instance=reader, name='reader')\n",
    "\n",
    "pipe.connect('retriever.documents', 'reader.documents')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_result = pipe.run(\n",
    "    data = {\n",
    "        'retriever': {\n",
    "            'query': question,\n",
    "            'top_k': 3\n",
    "        },\n",
    "        'reader': {\n",
    "            'query': question,\n",
    "            'top_k': 3\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: How much music can this hold?\n",
      "- stream if a phone call comes in at the same time\n",
      "- 12oz\n",
      "- the tiny unit can play music streamed via Bluetooth from both my iPhone and iPad anywhere in my apartment\n",
      "- None\n"
     ]
    }
   ],
   "source": [
    "print('Q:', question)\n",
    "for ans in run_result['reader']['answers']:\n",
    "    print('-', ans.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "## HF pipeline\n",
    "pros: straight forward, easy to use.\n",
    "- Usage: `pipe(question, context)`\n",
    "\n",
    "cons: only works if you have the context ready.\n",
    "\n",
    "## QA pipeline\n",
    "Retriever: parse, dense.\n",
    "- sparse: use word frequency (like TF-IDF)\n",
    "- dense: use word embedding\n",
    "\n",
    "Reader: extract answers from retrived documents.\n",
    "\n",
    "Document store: sparse (tf-idf, BM25), dense(embedding, DPR).\n",
    "\n",
    "**Evaluate performance**\n",
    "- EM: exact match. stricter\n",
    "- F1: f1 score. more relaxed\n",
    "Relying on F1 only can be misleading -> track both metrics.\n",
    "\n",
    "## Fine-tuning (domain adaptation)\n",
    "SQuAD pipieline performs poorly on SubjQA. \n",
    "\n",
    "Fine-tuned on SQuAD and SubjQA yieds significant performance.\n",
    "\n",
    "Q: why we don't fine-tune on SubjQA?\n",
    "\n",
    "A: SubjQA has only over 1,000 samples which can lead to overfitting. SQuAD has over 100,000 samples.\n",
    "\n",
    "<img src=\"./qa-perf.png\" width=\"500px\"> </img>\n",
    "\n",
    "## RAG\n",
    "- RAG is *generative* QA, while the above approach is called *extractive*.\n",
    "- relies on dense vector embedding (both document and question).\n",
    "- reader -> generator: generates passage from matched docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
